{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6ff5c35",
   "metadata": {},
   "source": [
    "# Dataset Sushil\n",
    "###### src=\"@INPROCEEDINGS{10455077, author={Dalavi, Sushil and Nivelkar, Tanvesh and Patil, Sarvesh and Sawant, Aadesh and Vanwari, Pankaj}, booktitle={2023 6th International Conference on Advances in Science and Technology (ICAST)}, title={Enhancing Hate Speech Detection through Emoji-based Classification using Bi-LSTM and GloVe Embeddings}, year={2023}, volume={}, number={}, pages={506-511}, keywords={Deep learning;Video on demand;Social networking (online);Hate speech;Web sites;Task analysis;Emojis;Emoji-based hate speech model;TfidfVectorizer;GloVe;Bi-LSTM;networking;abusive}, doi={10.1109/ICAST59062.2023.10455077}}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2fc6f9",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17487b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import html\n",
    "import emoji\n",
    "from collections import Counter\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3baae208",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf64c869",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5934b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_emoji(text):\n",
    "    return isinstance(text, str) and bool(emoji.emoji_list(text))\n",
    "\n",
    "def extract_emojis(text):\n",
    "    return [e[\"emoji\"] for e in emoji.emoji_list(text)]\n",
    "\n",
    "def format_emojis(emojis):\n",
    "    return \" \".join(emojis) if isinstance(emojis, list) else emojis\n",
    "\n",
    "def get_most_least_common_emojis(df, emoji_column=\"emoji\", top_n=1):\n",
    "    all_emojis = [e for em in df[emoji_column] for e in em.split()]\n",
    "    counts = Counter(all_emojis)\n",
    "    return counts.most_common(top_n), counts.most_common()[-top_n:]\n",
    "\n",
    "def get_most_common_emojis_by_label(df, emoji_column=\"emoji\", label_column=\"labels\", top_n=10):\n",
    "    result = {}\n",
    "    for label in df[label_column].unique():\n",
    "        emojis = [e for em in df[df[label_column] == label][emoji_column] for e in em.split()]\n",
    "        result[label] = Counter(emojis).most_common(top_n)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8572e58",
   "metadata": {},
   "source": [
    "## Main Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68e9b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sushil_dataset(file1, file2, output_csv=\"dataset/Sushil/train_emoji.csv\"):\n",
    "    # Load and clean Dataset 1\n",
    "    df1 = pd.read_excel(file1, header=None, names=[\"tweets\", \"labels\"])\n",
    "    df1[\"tweets\"] = df1[\"tweets\"].apply(html.unescape)\n",
    "    df1[\"labels\"] = df1[\"labels\"].replace({'normal': 0, 'hateful': 1})\n",
    "\n",
    "    # Load and relabel Dataset 2\n",
    "    df2 = pd.read_excel(file2)\n",
    "    df2[\"labels\"] = df2[\"labels\"].replace({1: 0, 0: 1})\n",
    "\n",
    "    # Combine\n",
    "    df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    # Emoji filtering\n",
    "    df = df[df[\"tweets\"].apply(contains_emoji)].copy()\n",
    "    df[\"emoji\"] = df[\"tweets\"].apply(extract_emojis).apply(format_emojis)\n",
    "\n",
    "    # Save cleaned CSV\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved emoji-processed dataset to: {output_csv}\")\n",
    "\n",
    "    # Emoji analysis\n",
    "    most_common, least_common = get_most_least_common_emojis(df)\n",
    "    print(\"Most common emoji:\", most_common)\n",
    "    print(\"Least common emoji:\", least_common)\n",
    "\n",
    "    emoji_by_label = get_most_common_emojis_by_label(df)\n",
    "    for label, items in emoji_by_label.items():\n",
    "        print(f\"\\nTop emojis for label {label}: {items}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38954066",
   "metadata": {},
   "source": [
    "## Train and Test Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b56d473a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved emoji-processed dataset to: dataset/Sushil/train_emoji.csv\n",
      "Most common emoji: [('üòÇ', 6869)]\n",
      "Least common emoji: [('‚ñ™', 1)]\n",
      "\n",
      "Top emojis for label 0: [('üò≠', 3851), ('üòÇ', 3586), ('üòç', 1302), ('üòä', 1176), ('üî•', 1128), ('üò±', 682), ('‚ù§', 598), ('üòò', 528), ('üò¢', 527), ('üò©', 502)]\n",
      "\n",
      "Top emojis for label 1: [('üòÇ', 3283), ('üò≠', 1298), ('üòç', 431), ('üò©', 417), ('üî•', 375), ('üôÑ', 308), ('üíÄ', 279), ('üëÖ', 251), ('üíØ', 222), ('üò°', 203)]\n"
     ]
    }
   ],
   "source": [
    "# === Run ===\n",
    "df_emoji = process_sushil_dataset(\"dataset/Sushil/Dataset 1.xlsx\", \"dataset/Sushil/Dataset 2.xlsx\", \"dataset/Sushil/train_emoji.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
All PyTorch model weights were used when initializing TFBertForSequenceClassification.

Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
âœ… GPU detected. Training will use GPU.

Running experiment with batch_size=16, learning_rate=5e-05, epochs=2

Epoch 1/2
Train Loss: 0.6903 | Val Loss: 0.6847 | Time: 147.76s
Train Loss: 0.6993 | Val Loss: 0.6895 | Time: 282.47s
Train Loss: 0.7137 | Val Loss: 0.6768 | Time: 426.26s
Train Loss: 0.7126 | Val Loss: 0.6721 | Time: 566.45s
Train Loss: 0.7061 | Val Loss: 0.6738 | Time: 710.84s
Train Loss: 0.6982 | Val Loss: 0.6818 | Time: 838.90s
Train Loss: 0.7028 | Val Loss: 0.6847 | Time: 982.62s
Early stopping...

Epoch 2/2
Train Loss: 0.7560 | Val Loss: 0.6788 | Time: 144.69s
Early stopping...

Running experiment with batch_size=16, learning_rate=5e-05, epochs=3

Epoch 1/3
Train Loss: 0.7075 | Val Loss: 0.6937 | Time: 146.84s
Train Loss: 0.7137 | Val Loss: 0.6878 | Time: 273.87s
Train Loss: 0.7000 | Val Loss: 0.6825 | Time: 417.75s
Train Loss: 0.6976 | Val Loss: 0.6773 | Time: 551.41s
Train Loss: 0.6991 | Val Loss: 0.6727 | Time: 680.91s
Train Loss: 0.6949 | Val Loss: 0.6740 | Time: 808.60s
Train Loss: 0.6971 | Val Loss: 0.6725 | Time: 952.35s
Train Loss: 0.6933 | Val Loss: 0.6682 | Time: 1104.25s
Train Loss: 0.6956 | Val Loss: 0.6599 | Time: 1369.95s
Train Loss: 0.6920 | Val Loss: 0.6533 | Time: 1593.64s
Train Loss: 0.6916 | Val Loss: 0.6588 | Time: 1821.04s
Train Loss: 0.6857 | Val Loss: 0.6848 | Time: 2046.24s
Train Loss: 0.6889 | Val Loss: 0.7017 | Time: 2270.19s
Early stopping...

Epoch 2/3
Train Loss: 0.8257 | Val Loss: 0.6922 | Time: 228.85s
Early stopping...

Epoch 3/3
Train Loss: 0.7697 | Val Loss: 0.6722 | Time: 227.57s
Early stopping...

Running experiment with batch_size=16, learning_rate=5e-05, epochs=4

Epoch 1/4
Train Loss: 0.7278 | Val Loss: 0.6914 | Time: 226.36s
Train Loss: 0.7212 | Val Loss: 0.6934 | Time: 451.26s
Train Loss: 0.7005 | Val Loss: 0.6918 | Time: 716.88s
Train Loss: 0.6908 | Val Loss: 0.6920 | Time: 943.45s
Early stopping...

Epoch 2/4
Train Loss: 0.6966 | Val Loss: 0.7043 | Time: 266.27s
Early stopping...

Epoch 3/4
Train Loss: 0.7525 | Val Loss: 0.7023 | Time: 224.20s
Early stopping...

Epoch 4/4
Train Loss: 0.7265 | Val Loss: 0.6946 | Time: 243.47s
Early stopping...

Running experiment with batch_size=16, learning_rate=3e-05, epochs=2

Epoch 1/2
Train Loss: 0.7066 | Val Loss: 0.6998 | Time: 227.28s
Train Loss: 0.6965 | Val Loss: 0.7031 | Time: 492.27s
Train Loss: 0.7011 | Val Loss: 0.7035 | Time: 716.87s
Train Loss: 0.7047 | Val Loss: 0.6998 | Time: 982.22s
Early stopping...

Epoch 2/2
Train Loss: 0.7266 | Val Loss: 0.6939 | Time: 227.91s
Train Loss: 0.7019 | Val Loss: 0.6911 | Time: 458.65s
Train Loss: 0.7061 | Val Loss: 0.6884 | Time: 723.72s
Train Loss: 0.7057 | Val Loss: 0.6871 | Time: 949.55s
Train Loss: 0.7009 | Val Loss: 0.6866 | Time: 1171.42s
Train Loss: 0.6988 | Val Loss: 0.6851 | Time: 1437.16s
Train Loss: 0.6989 | Val Loss: 0.6835 | Time: 1675.53s
Train Loss: 0.6970 | Val Loss: 0.6817 | Time: 1940.25s
Train Loss: 0.6960 | Val Loss: 0.6800 | Time: 2204.58s
Train Loss: 0.6932 | Val Loss: 0.6777 | Time: 2429.66s
Train Loss: 0.6934 | Val Loss: 0.6748 | Time: 2653.24s
Train Loss: 0.6910 | Val Loss: 0.6723 | Time: 2874.52s
Train Loss: 0.6930 | Val Loss: 0.6688 | Time: 3098.85s
Train Loss: 0.6909 | Val Loss: 0.6670 | Time: 3326.78s
Train Loss: 0.6880 | Val Loss: 0.6669 | Time: 3554.29s
Train Loss: 0.6844 | Val Loss: 0.6694 | Time: 3819.02s
Train Loss: 0.6820 | Val Loss: 0.6719 | Time: 4042.36s
Early stopping...

Running experiment with batch_size=16, learning_rate=3e-05, epochs=3

Epoch 1/3
Train Loss: 0.6897 | Val Loss: 0.6985 | Time: 266.78s
Train Loss: 0.6791 | Val Loss: 0.6935 | Time: 491.88s
Train Loss: 0.6902 | Val Loss: 0.6895 | Time: 711.08s
Train Loss: 0.6846 | Val Loss: 0.6945 | Time: 976.36s
Train Loss: 0.6950 | Val Loss: 0.6949 | Time: 1240.71s
Train Loss: 0.6971 | Val Loss: 0.6950 | Time: 1461.65s
Early stopping...

Epoch 2/3
Train Loss: 0.7145 | Val Loss: 0.6938 | Time: 226.74s
Early stopping...

Epoch 3/3
Train Loss: 0.7282 | Val Loss: 0.6892 | Time: 228.34s
Train Loss: 0.7007 | Val Loss: 0.6873 | Time: 448.99s
Train Loss: 0.6976 | Val Loss: 0.6831 | Time: 713.29s
Train Loss: 0.6992 | Val Loss: 0.6781 | Time: 936.90s
Train Loss: 0.6942 | Val Loss: 0.6739 | Time: 1155.88s
Train Loss: 0.6928 | Val Loss: 0.6719 | Time: 1372.28s
Train Loss: 0.6918 | Val Loss: 0.6693 | Time: 1592.84s
Train Loss: 0.6898 | Val Loss: 0.6657 | Time: 1809.93s
Train Loss: 0.6854 | Val Loss: 0.6625 | Time: 2039.86s
Train Loss: 0.6848 | Val Loss: 0.6597 | Time: 2305.13s
Train Loss: 0.6840 | Val Loss: 0.6565 | Time: 2527.70s
Train Loss: 0.6834 | Val Loss: 0.6528 | Time: 2751.39s
Train Loss: 0.6799 | Val Loss: 0.6517 | Time: 2961.86s
Train Loss: 0.6787 | Val Loss: 0.6499 | Time: 3180.83s
Train Loss: 0.6786 | Val Loss: 0.6495 | Time: 3398.09s
Train Loss: 0.6746 | Val Loss: 0.6505 | Time: 3618.19s
Train Loss: 0.6738 | Val Loss: 0.6521 | Time: 3840.32s
Train Loss: 0.6760 | Val Loss: 0.6508 | Time: 4065.44s
Early stopping...

Running experiment with batch_size=16, learning_rate=3e-05, epochs=4

Epoch 1/4
Train Loss: 0.6924 | Val Loss: 0.6941 | Time: 227.85s
Train Loss: 0.7036 | Val Loss: 0.6886 | Time: 456.39s
Train Loss: 0.6996 | Val Loss: 0.6854 | Time: 676.16s
Train Loss: 0.6970 | Val Loss: 0.6842 | Time: 941.08s
Train Loss: 0.6965 | Val Loss: 0.6822 | Time: 1163.14s
Train Loss: 0.6944 | Val Loss: 0.6818 | Time: 1386.52s
Train Loss: 0.6919 | Val Loss: 0.6805 | Time: 1609.72s
Train Loss: 0.6927 | Val Loss: 0.6792 | Time: 1828.31s
Train Loss: 0.6922 | Val Loss: 0.6772 | Time: 2056.74s
Train Loss: 0.6916 | Val Loss: 0.6757 | Time: 2322.23s
Train Loss: 0.6937 | Val Loss: 0.6733 | Time: 2549.22s
Train Loss: 0.6931 | Val Loss: 0.6708 | Time: 2771.44s
Train Loss: 0.6929 | Val Loss: 0.6692 | Time: 2997.51s
Train Loss: 0.6913 | Val Loss: 0.6682 | Time: 3225.45s
Train Loss: 0.6919 | Val Loss: 0.6676 | Time: 3449.28s
Train Loss: 0.6892 | Val Loss: 0.6666 | Time: 3669.77s
Train Loss: 0.6889 | Val Loss: 0.6658 | Time: 3889.80s
Train Loss: 0.6888 | Val Loss: 0.6650 | Time: 4155.21s
Train Loss: 0.6887 | Val Loss: 0.6631 | Time: 4384.57s
Train Loss: 0.6865 | Val Loss: 0.6612 | Time: 4610.97s
Train Loss: 0.6865 | Val Loss: 0.6586 | Time: 4835.07s
Train Loss: 0.6876 | Val Loss: 0.6567 | Time: 5101.11s
Train Loss: 0.6864 | Val Loss: 0.6542 | Time: 5367.37s
Train Loss: 0.6855 | Val Loss: 0.6507 | Time: 5632.74s
Train Loss: 0.6857 | Val Loss: 0.6490 | Time: 5859.95s
Train Loss: 0.6847 | Val Loss: 0.6503 | Time: 6081.98s
Train Loss: 0.6856 | Val Loss: 0.6547 | Time: 6306.90s
Train Loss: 0.6854 | Val Loss: 0.6588 | Time: 6535.73s
Early stopping...

Epoch 2/4
Train Loss: 0.6341 | Val Loss: 0.6668 | Time: 231.67s
Early stopping...

Epoch 3/4
Train Loss: 0.6566 | Val Loss: 0.6757 | Time: 266.45s
Early stopping...

Epoch 4/4
Train Loss: 0.5771 | Val Loss: 0.6916 | Time: 266.66s
Early stopping...

Running experiment with batch_size=16, learning_rate=2e-05, epochs=2

Epoch 1/2
Train Loss: 0.7030 | Val Loss: 0.6995 | Time: 268.64s
Train Loss: 0.7002 | Val Loss: 0.7007 | Time: 491.97s
Train Loss: 0.7093 | Val Loss: 0.7004 | Time: 721.61s
Train Loss: 0.7039 | Val Loss: 0.6995 | Time: 945.58s
Early stopping...

Epoch 2/2
Train Loss: 0.6969 | Val Loss: 0.6984 | Time: 226.85s
Train Loss: 0.6795 | Val Loss: 0.6986 | Time: 492.92s
Train Loss: 0.6838 | Val Loss: 0.6988 | Time: 758.33s
Train Loss: 0.6900 | Val Loss: 0.6961 | Time: 982.45s
Train Loss: 0.6897 | Val Loss: 0.6924 | Time: 1197.65s
Train Loss: 0.6927 | Val Loss: 0.6885 | Time: 1417.47s
Train Loss: 0.6875 | Val Loss: 0.6861 | Time: 1683.46s
Train Loss: 0.6947 | Val Loss: 0.6829 | Time: 1912.46s
Train Loss: 0.6915 | Val Loss: 0.6806 | Time: 2171.73s
Train Loss: 0.6895 | Val Loss: 0.6784 | Time: 2398.83s
Train Loss: 0.6905 | Val Loss: 0.6771 | Time: 2625.23s
Train Loss: 0.6897 | Val Loss: 0.6768 | Time: 2853.51s
Train Loss: 0.6892 | Val Loss: 0.6766 | Time: 3119.34s
Train Loss: 0.6894 | Val Loss: 0.6758 | Time: 3384.87s
Train Loss: 0.6894 | Val Loss: 0.6750 | Time: 3611.66s
Train Loss: 0.6905 | Val Loss: 0.6742 | Time: 3877.74s
Train Loss: 0.6903 | Val Loss: 0.6736 | Time: 4097.41s
Train Loss: 0.6910 | Val Loss: 0.6723 | Time: 4323.03s
Train Loss: 0.6898 | Val Loss: 0.6710 | Time: 4543.53s
Train Loss: 0.6902 | Val Loss: 0.6696 | Time: 4762.10s
Train Loss: 0.6906 | Val Loss: 0.6683 | Time: 4984.74s
Train Loss: 0.6908 | Val Loss: 0.6670 | Time: 5249.34s
Train Loss: 0.6908 | Val Loss: 0.6659 | Time: 5425.07s
Train Loss: 0.6908 | Val Loss: 0.6651 | Time: 5553.02s
Train Loss: 0.6900 | Val Loss: 0.6636 | Time: 5696.76s
Train Loss: 0.6903 | Val Loss: 0.6625 | Time: 5825.61s
Train Loss: 0.6900 | Val Loss: 0.6611 | Time: 5969.58s
Train Loss: 0.6895 | Val Loss: 0.6600 | Time: 6097.83s
Train Loss: 0.6892 | Val Loss: 0.6585 | Time: 6224.21s
Train Loss: 0.6894 | Val Loss: 0.6574 | Time: 6368.19s
Train Loss: 0.6878 | Val Loss: 0.6557 | Time: 6497.54s
Train Loss: 0.6871 | Val Loss: 0.6532 | Time: 6642.30s
Train Loss: 0.6868 | Val Loss: 0.6507 | Time: 6786.22s
Train Loss: 0.6862 | Val Loss: 0.6483 | Time: 6913.63s
Train Loss: 0.6860 | Val Loss: 0.6456 | Time: 7057.51s
Train Loss: 0.6860 | Val Loss: 0.6437 | Time: 7201.43s
Train Loss: 0.6852 | Val Loss: 0.6420 | Time: 7328.84s
Train Loss: 0.6843 | Val Loss: 0.6388 | Time: 7458.05s
Train Loss: 0.6848 | Val Loss: 0.6355 | Time: 7586.35s
Train Loss: 0.6855 | Val Loss: 0.6339 | Time: 7712.84s
Train Loss: 0.6852 | Val Loss: 0.6328 | Time: 7856.35s
Train Loss: 0.6835 | Val Loss: 0.6316 | Time: 8000.13s
Train Loss: 0.6832 | Val Loss: 0.6301 | Time: 8130.74s
Train Loss: 0.6812 | Val Loss: 0.6281 | Time: 8256.56s
Train Loss: 0.6801 | Val Loss: 0.6269 | Time: 8400.17s
Train Loss: 0.6795 | Val Loss: 0.6258 | Time: 8543.98s
Train Loss: 0.6789 | Val Loss: 0.6264 | Time: 8669.66s
Train Loss: 0.6777 | Val Loss: 0.6265 | Time: 8797.69s
Train Loss: 0.6775 | Val Loss: 0.6271 | Time: 8941.58s
Early stopping...

Running experiment with batch_size=16, learning_rate=2e-05, epochs=3

Epoch 1/3
Train Loss: 0.7164 | Val Loss: 0.6913 | Time: 130.34s
Train Loss: 0.7001 | Val Loss: 0.6896 | Time: 274.39s
Train Loss: 0.6907 | Val Loss: 0.6888 | Time: 418.13s
Train Loss: 0.6943 | Val Loss: 0.6890 | Time: 562.06s
Train Loss: 0.6946 | Val Loss: 0.6882 | Time: 688.76s
Train Loss: 0.6994 | Val Loss: 0.6870 | Time: 815.88s
Train Loss: 0.6971 | Val Loss: 0.6855 | Time: 959.74s
Train Loss: 0.6946 | Val Loss: 0.6843 | Time: 1103.59s
Train Loss: 0.6930 | Val Loss: 0.6830 | Time: 1231.93s
Train Loss: 0.6918 | Val Loss: 0.6810 | Time: 1375.86s
Train Loss: 0.6897 | Val Loss: 0.6792 | Time: 1580.16s
Train Loss: 0.6894 | Val Loss: 0.6787 | Time: 1728.51s
Train Loss: 0.6905 | Val Loss: 0.6785 | Time: 1932.62s
Train Loss: 0.6901 | Val Loss: 0.6786 | Time: 2136.87s
Train Loss: 0.6894 | Val Loss: 0.6789 | Time: 2287.36s
Train Loss: 0.6909 | Val Loss: 0.6785 | Time: 2491.36s
Early stopping...

Epoch 2/3
Train Loss: 0.6956 | Val Loss: 0.6779 | Time: 150.78s
Train Loss: 0.6999 | Val Loss: 0.6765 | Time: 295.70s
Train Loss: 0.6997 | Val Loss: 0.6748 | Time: 499.79s
Train Loss: 0.6979 | Val Loss: 0.6730 | Time: 649.61s
Train Loss: 0.6958 | Val Loss: 0.6714 | Time: 863.60s
Train Loss: 0.6970 | Val Loss: 0.6696 | Time: 1053.32s
Train Loss: 0.6978 | Val Loss: 0.6681 | Time: 1240.61s
Train Loss: 0.6963 | Val Loss: 0.6667 | Time: 1429.23s
Train Loss: 0.6910 | Val Loss: 0.6650 | Time: 1634.11s
Train Loss: 0.6928 | Val Loss: 0.6637 | Time: 1764.17s
Train Loss: 0.6933 | Val Loss: 0.6632 | Time: 1893.86s
Train Loss: 0.6964 | Val Loss: 0.6629 | Time: 2037.64s
Train Loss: 0.6937 | Val Loss: 0.6614 | Time: 2166.03s
Train Loss: 0.6930 | Val Loss: 0.6586 | Time: 2294.88s
Train Loss: 0.6914 | Val Loss: 0.6551 | Time: 2424.19s
Train Loss: 0.6894 | Val Loss: 0.6520 | Time: 2554.95s
Train Loss: 0.6881 | Val Loss: 0.6489 | Time: 2684.61s
Train Loss: 0.6869 | Val Loss: 0.6468 | Time: 2828.30s
Train Loss: 0.6842 | Val Loss: 0.6448 | Time: 2959.58s
Train Loss: 0.6829 | Val Loss: 0.6429 | Time: 3103.42s
Train Loss: 0.6801 | Val Loss: 0.6409 | Time: 3247.22s
Train Loss: 0.6805 | Val Loss: 0.6402 | Time: 3379.79s
Train Loss: 0.6805 | Val Loss: 0.6406 | Time: 3513.14s
Train Loss: 0.6803 | Val Loss: 0.6372 | Time: 3657.13s
Train Loss: 0.6794 | Val Loss: 0.6337 | Time: 3785.22s
Train Loss: 0.6769 | Val Loss: 0.6293 | Time: 3929.15s
Train Loss: 0.6761 | Val Loss: 0.6236 | Time: 4073.01s
Train Loss: 0.6754 | Val Loss: 0.6178 | Time: 4202.55s
Train Loss: 0.6731 | Val Loss: 0.6128 | Time: 4332.30s
Train Loss: 0.6734 | Val Loss: 0.6070 | Time: 4463.47s
Train Loss: 0.6727 | Val Loss: 0.6013 | Time: 4597.73s
Train Loss: 0.6720 | Val Loss: 0.5974 | Time: 4741.98s
Train Loss: 0.6729 | Val Loss: 0.5941 | Time: 4875.46s
Train Loss: 0.6720 | Val Loss: 0.5912 | Time: 5019.52s
Train Loss: 0.6750 | Val Loss: 0.5880 | Time: 5163.47s
Train Loss: 0.6723 | Val Loss: 0.5841 | Time: 5291.66s
Train Loss: 0.6715 | Val Loss: 0.5806 | Time: 5435.43s
Train Loss: 0.6708 | Val Loss: 0.5754 | Time: 5579.27s
Train Loss: 0.6685 | Val Loss: 0.5695 | Time: 5706.64s
Train Loss: 0.6658 | Val Loss: 0.5634 | Time: 5835.40s
Train Loss: 0.6668 | Val Loss: 0.5589 | Time: 5979.28s
Train Loss: 0.6649 | Val Loss: 0.5614 | Time: 6108.62s
Train Loss: 0.6642 | Val Loss: 0.5660 | Time: 6233.67s
Train Loss: 0.6647 | Val Loss: 0.5696 | Time: 6360.50s
Early stopping...

Epoch 3/3
Train Loss: 0.6545 | Val Loss: 0.5624 | Time: 133.23s
Early stopping...

Running experiment with batch_size=16, learning_rate=2e-05, epochs=4

Epoch 1/4
Train Loss: 0.7003 | Val Loss: 0.6962 | Time: 131.00s
Train Loss: 0.6854 | Val Loss: 0.6996 | Time: 276.00s
Train Loss: 0.6934 | Val Loss: 0.7012 | Time: 419.98s
Train Loss: 0.7020 | Val Loss: 0.6986 | Time: 552.74s
Early stopping...

Epoch 2/4
Train Loss: 0.6752 | Val Loss: 0.6969 | Time: 133.37s
Early stopping...

Epoch 3/4
Train Loss: 0.6905 | Val Loss: 0.6960 | Time: 144.53s
Train Loss: 0.6628 | Val Loss: 0.6967 | Time: 273.34s
Train Loss: 0.6678 | Val Loss: 0.6986 | Time: 417.31s
Train Loss: 0.6797 | Val Loss: 0.6985 | Time: 545.64s
Early stopping...

Epoch 4/4
Train Loss: 0.7169 | Val Loss: 0.6969 | Time: 144.48s
Early stopping...

Running experiment with batch_size=32, learning_rate=5e-05, epochs=2

Epoch 1/2
Train Loss: 0.6918 | Val Loss: 0.6821 | Time: 85.42s
Train Loss: 0.6886 | Val Loss: 0.6796 | Time: 147.73s
Train Loss: 0.6903 | Val Loss: 0.6791 | Time: 230.82s
Train Loss: 0.6887 | Val Loss: 0.6797 | Time: 314.70s
Train Loss: 0.6946 | Val Loss: 0.6743 | Time: 380.06s
Train Loss: 0.6895 | Val Loss: 0.6662 | Time: 448.15s
Train Loss: 0.6881 | Val Loss: 0.6611 | Time: 515.33s
Train Loss: 0.6867 | Val Loss: 0.6584 | Time: 580.97s
Train Loss: 0.6868 | Val Loss: 0.6510 | Time: 664.86s
Train Loss: 0.6854 | Val Loss: 0.6448 | Time: 731.17s
Train Loss: 0.6831 | Val Loss: 0.6397 | Time: 815.19s
Train Loss: 0.6816 | Val Loss: 0.6334 | Time: 899.06s
Train Loss: 0.6808 | Val Loss: 0.6228 | Time: 966.57s
Train Loss: 0.6798 | Val Loss: 0.6138 | Time: 1050.76s
Train Loss: 0.6801 | Val Loss: 0.6072 | Time: 1118.64s
Train Loss: 0.6804 | Val Loss: 0.6133 | Time: 1186.58s
Train Loss: 0.6787 | Val Loss: 0.6508 | Time: 1270.52s
Train Loss: 0.6793 | Val Loss: 0.6798 | Time: 1337.52s
Early stopping...

Epoch 2/2
Train Loss: 0.6682 | Val Loss: 0.6742 | Time: 67.30s
Early stopping...

Running experiment with batch_size=32, learning_rate=5e-05, epochs=3

Epoch 1/3
Train Loss: 0.7042 | Val Loss: 0.7049 | Time: 68.44s
Train Loss: 0.6935 | Val Loss: 0.7051 | Time: 137.29s
Train Loss: 0.6919 | Val Loss: 0.7055 | Time: 221.22s
Train Loss: 0.6961 | Val Loss: 0.6919 | Time: 288.84s
Train Loss: 0.6961 | Val Loss: 0.6778 | Time: 372.88s
Train Loss: 0.6911 | Val Loss: 0.6691 | Time: 440.98s
Train Loss: 0.6886 | Val Loss: 0.6705 | Time: 524.91s
Train Loss: 0.6850 | Val Loss: 0.6821 | Time: 608.83s
Train Loss: 0.6845 | Val Loss: 0.6991 | Time: 676.28s
Early stopping...

Epoch 2/3
Train Loss: 0.6930 | Val Loss: 0.6956 | Time: 66.71s
Early stopping...

Epoch 3/3
Train Loss: 0.7344 | Val Loss: 0.6604 | Time: 84.76s
Train Loss: 0.7179 | Val Loss: 0.6348 | Time: 151.05s
Train Loss: 0.7021 | Val Loss: 0.6346 | Time: 217.07s
Train Loss: 0.6947 | Val Loss: 0.6353 | Time: 301.09s
Train Loss: 0.6901 | Val Loss: 0.6301 | Time: 366.83s
Train Loss: 0.6855 | Val Loss: 0.6243 | Time: 433.73s
Train Loss: 0.6820 | Val Loss: 0.6109 | Time: 499.46s
Train Loss: 0.6801 | Val Loss: 0.6041 | Time: 566.61s
Train Loss: 0.6760 | Val Loss: 0.5997 | Time: 650.67s
Train Loss: 0.6825 | Val Loss: 0.5927 | Time: 719.79s
Train Loss: 0.6789 | Val Loss: 0.5901 | Time: 789.46s
Train Loss: 0.6750 | Val Loss: 0.5861 | Time: 856.45s
Train Loss: 0.6742 | Val Loss: 0.5823 | Time: 922.73s
Train Loss: 0.6711 | Val Loss: 0.5779 | Time: 987.98s
Train Loss: 0.6648 | Val Loss: 0.5710 | Time: 1071.88s
Train Loss: 0.6604 | Val Loss: 0.5615 | Time: 1155.76s
Train Loss: 0.6607 | Val Loss: 0.5617 | Time: 1222.22s
Train Loss: 0.6584 | Val Loss: 0.5827 | Time: 1287.73s
Train Loss: 0.6499 | Val Loss: 0.6177 | Time: 1371.61s
Early stopping...

Running experiment with batch_size=32, learning_rate=5e-05, epochs=4

Epoch 1/4
Train Loss: 0.7810 | Val Loss: 0.6972 | Time: 86.98s
Train Loss: 0.7342 | Val Loss: 0.6963 | Time: 154.24s
Train Loss: 0.7198 | Val Loss: 0.6938 | Time: 220.85s
Train Loss: 0.7138 | Val Loss: 0.6909 | Time: 304.69s
Train Loss: 0.7171 | Val Loss: 0.6798 | Time: 388.73s
Train Loss: 0.7150 | Val Loss: 0.6783 | Time: 472.76s
Train Loss: 0.7109 | Val Loss: 0.6757 | Time: 539.46s
Train Loss: 0.7074 | Val Loss: 0.6719 | Time: 623.43s
Train Loss: 0.7047 | Val Loss: 0.6692 | Time: 689.34s
Train Loss: 0.7026 | Val Loss: 0.6694 | Time: 773.34s
Train Loss: 0.6995 | Val Loss: 0.6669 | Time: 857.48s
Train Loss: 0.7000 | Val Loss: 0.6618 | Time: 921.91s
Train Loss: 0.6948 | Val Loss: 0.6571 | Time: 1006.00s
Train Loss: 0.6906 | Val Loss: 0.6568 | Time: 1073.94s
Train Loss: 0.6929 | Val Loss: 0.6476 | Time: 1139.41s
Train Loss: 0.6911 | Val Loss: 0.6365 | Time: 1208.67s
Train Loss: 0.6923 | Val Loss: 0.6257 | Time: 1275.61s
Train Loss: 0.6910 | Val Loss: 0.6183 | Time: 1359.54s
Train Loss: 0.6889 | Val Loss: 0.6099 | Time: 1443.49s
Train Loss: 0.6861 | Val Loss: 0.6013 | Time: 1527.43s
Train Loss: 0.6838 | Val Loss: 0.5890 | Time: 1596.13s
Train Loss: 0.6835 | Val Loss: 0.5796 | Time: 1680.49s
Train Loss: 0.6818 | Val Loss: 0.5677 | Time: 1746.63s
Train Loss: 0.6789 | Val Loss: 0.5574 | Time: 1813.81s
Train Loss: 0.6735 | Val Loss: 0.5451 | Time: 1857.55s
Train Loss: 0.6702 | Val Loss: 0.5338 | Time: 1908.40s
Train Loss: 0.6691 | Val Loss: 0.5298 | Time: 1985.58s
Train Loss: 0.6678 | Val Loss: 0.5303 | Time: 2063.75s
Train Loss: 0.6633 | Val Loss: 0.5388 | Time: 2140.17s
Train Loss: 0.6586 | Val Loss: 0.5266 | Time: 2218.24s
Train Loss: 0.6579 | Val Loss: 0.5104 | Time: 2302.86s
Train Loss: 0.6529 | Val Loss: 0.5897 | Time: 2381.36s
Train Loss: 0.6528 | Val Loss: 0.6138 | Time: 2465.51s
Train Loss: 0.6489 | Val Loss: 0.5275 | Time: 2549.94s
Early stopping...

Epoch 2/4
Train Loss: 0.5548 | Val Loss: 0.4972 | Time: 76.57s
Train Loss: 0.5302 | Val Loss: 0.5314 | Time: 160.86s
Train Loss: 0.5608 | Val Loss: 0.5214 | Time: 245.02s
Train Loss: 0.5548 | Val Loss: 0.4964 | Time: 321.31s
Train Loss: 0.5506 | Val Loss: 0.5267 | Time: 397.68s
Train Loss: 0.5629 | Val Loss: 0.5429 | Time: 473.18s
Train Loss: 0.5327 | Val Loss: 0.5704 | Time: 557.40s
Early stopping...

Epoch 3/4
Train Loss: 0.5608 | Val Loss: 0.5799 | Time: 77.99s
Early stopping...

Epoch 4/4
Train Loss: 0.7444 | Val Loss: 0.5456 | Time: 85.17s
Early stopping...

Running experiment with batch_size=32, learning_rate=3e-05, epochs=2

Epoch 1/2
Train Loss: 0.6995 | Val Loss: 0.6958 | Time: 86.47s
Train Loss: 0.7082 | Val Loss: 0.6954 | Time: 172.01s
Train Loss: 0.7064 | Val Loss: 0.6935 | Time: 251.14s
Train Loss: 0.7006 | Val Loss: 0.6933 | Time: 335.33s
Train Loss: 0.7037 | Val Loss: 0.6913 | Time: 414.26s
Train Loss: 0.7004 | Val Loss: 0.6873 | Time: 498.48s
Train Loss: 0.6994 | Val Loss: 0.6822 | Time: 575.25s
Train Loss: 0.6953 | Val Loss: 0.6777 | Time: 652.80s
Train Loss: 0.6955 | Val Loss: 0.6728 | Time: 737.21s
Train Loss: 0.6912 | Val Loss: 0.6690 | Time: 814.15s
Train Loss: 0.6900 | Val Loss: 0.6661 | Time: 898.26s
Train Loss: 0.6885 | Val Loss: 0.6637 | Time: 982.59s
Train Loss: 0.6887 | Val Loss: 0.6623 | Time: 1060.57s
Train Loss: 0.6877 | Val Loss: 0.6617 | Time: 1138.48s
Train Loss: 0.6888 | Val Loss: 0.6590 | Time: 1222.90s
Train Loss: 0.6872 | Val Loss: 0.6561 | Time: 1307.15s
Train Loss: 0.6853 | Val Loss: 0.6540 | Time: 1382.45s
Train Loss: 0.6833 | Val Loss: 0.6499 | Time: 1466.87s
Train Loss: 0.6842 | Val Loss: 0.6436 | Time: 1544.60s
Train Loss: 0.6819 | Val Loss: 0.6391 | Time: 1628.70s
Train Loss: 0.6842 | Val Loss: 0.6319 | Time: 1713.19s
Train Loss: 0.6838 | Val Loss: 0.6249 | Time: 1791.93s
Train Loss: 0.6832 | Val Loss: 0.6209 | Time: 1876.40s
Train Loss: 0.6825 | Val Loss: 0.6217 | Time: 1954.53s
Train Loss: 0.6806 | Val Loss: 0.6310 | Time: 2038.72s
Train Loss: 0.6761 | Val Loss: 0.6520 | Time: 2116.98s
Early stopping...

Epoch 2/2
Train Loss: 0.6964 | Val Loss: 0.6735 | Time: 79.83s
Early stopping...

Running experiment with batch_size=32, learning_rate=3e-05, epochs=3

Epoch 1/3
Train Loss: 0.6808 | Val Loss: 0.6889 | Time: 78.72s
Train Loss: 0.6843 | Val Loss: 0.6917 | Time: 159.11s
Train Loss: 0.6780 | Val Loss: 0.6943 | Time: 243.51s
Train Loss: 0.6740 | Val Loss: 0.7006 | Time: 323.85s
Early stopping...

Epoch 2/3
Train Loss: 0.6936 | Val Loss: 0.7005 | Time: 85.19s
Early stopping...

Epoch 3/3
Train Loss: 0.7245 | Val Loss: 0.6929 | Time: 84.67s
Early stopping...

Running experiment with batch_size=32, learning_rate=3e-05, epochs=4

Epoch 1/4
Train Loss: 0.6972 | Val Loss: 0.6957 | Time: 82.60s
Train Loss: 0.7033 | Val Loss: 0.6935 | Time: 162.00s
Train Loss: 0.7025 | Val Loss: 0.6900 | Time: 246.27s
Train Loss: 0.7007 | Val Loss: 0.6879 | Time: 327.48s
Train Loss: 0.6981 | Val Loss: 0.6861 | Time: 412.21s
Train Loss: 0.6967 | Val Loss: 0.6847 | Time: 496.50s
Train Loss: 0.6986 | Val Loss: 0.6832 | Time: 580.66s
Train Loss: 0.6967 | Val Loss: 0.6807 | Time: 665.18s
Train Loss: 0.6967 | Val Loss: 0.6777 | Time: 749.62s
Train Loss: 0.6945 | Val Loss: 0.6745 | Time: 833.90s
Train Loss: 0.6940 | Val Loss: 0.6711 | Time: 918.21s
Train Loss: 0.6923 | Val Loss: 0.6687 | Time: 1002.73s
Train Loss: 0.6917 | Val Loss: 0.6667 | Time: 1079.34s
Train Loss: 0.6934 | Val Loss: 0.6653 | Time: 1163.65s
Train Loss: 0.6899 | Val Loss: 0.6655 | Time: 1248.00s
Train Loss: 0.6889 | Val Loss: 0.6678 | Time: 1332.12s
Train Loss: 0.6866 | Val Loss: 0.6723 | Time: 1409.94s
Early stopping...

Epoch 2/4
Train Loss: 0.6773 | Val Loss: 0.6796 | Time: 78.58s
Early stopping...

Epoch 3/4
Train Loss: 0.6852 | Val Loss: 0.6806 | Time: 77.08s
Early stopping...

Epoch 4/4
Train Loss: 0.6932 | Val Loss: 0.6724 | Time: 85.10s
Early stopping...

Running experiment with batch_size=32, learning_rate=2e-05, epochs=2

Epoch 1/2
Train Loss: 0.7183 | Val Loss: 0.6951 | Time: 79.65s
Train Loss: 0.7059 | Val Loss: 0.6934 | Time: 155.81s
Train Loss: 0.6949 | Val Loss: 0.6914 | Time: 232.35s
Train Loss: 0.6986 | Val Loss: 0.6897 | Time: 310.57s
Train Loss: 0.6965 | Val Loss: 0.6886 | Time: 394.94s
Train Loss: 0.6951 | Val Loss: 0.6885 | Time: 472.81s
Train Loss: 0.6952 | Val Loss: 0.6890 | Time: 556.03s
Train Loss: 0.6952 | Val Loss: 0.6900 | Time: 633.69s
Train Loss: 0.6922 | Val Loss: 0.6917 | Time: 718.11s
Early stopping...

Epoch 2/2
Train Loss: 0.6918 | Val Loss: 0.6932 | Time: 84.73s
Early stopping...

Running experiment with batch_size=32, learning_rate=2e-05, epochs=3

Epoch 1/3
Train Loss: 0.6973 | Val Loss: 0.6934 | Time: 86.27s
Train Loss: 0.6963 | Val Loss: 0.6960 | Time: 161.53s
Train Loss: 0.6971 | Val Loss: 0.6936 | Time: 245.83s
Train Loss: 0.6979 | Val Loss: 0.6888 | Time: 322.14s
Train Loss: 0.6985 | Val Loss: 0.6835 | Time: 397.60s
Train Loss: 0.6941 | Val Loss: 0.6796 | Time: 482.02s
Train Loss: 0.6932 | Val Loss: 0.6758 | Time: 557.75s
Train Loss: 0.6909 | Val Loss: 0.6732 | Time: 633.08s
Train Loss: 0.6915 | Val Loss: 0.6706 | Time: 710.39s
Train Loss: 0.6907 | Val Loss: 0.6680 | Time: 787.81s
Train Loss: 0.6889 | Val Loss: 0.6646 | Time: 864.18s
Train Loss: 0.6868 | Val Loss: 0.6618 | Time: 941.41s
Train Loss: 0.6855 | Val Loss: 0.6596 | Time: 1020.02s
Train Loss: 0.6874 | Val Loss: 0.6573 | Time: 1097.39s
Train Loss: 0.6862 | Val Loss: 0.6554 | Time: 1174.61s
Train Loss: 0.6854 | Val Loss: 0.6541 | Time: 1251.33s
Train Loss: 0.6853 | Val Loss: 0.6531 | Time: 1335.64s
Train Loss: 0.6853 | Val Loss: 0.6530 | Time: 1419.72s
Train Loss: 0.6835 | Val Loss: 0.6534 | Time: 1503.94s
Train Loss: 0.6837 | Val Loss: 0.6544 | Time: 1581.09s
Train Loss: 0.6842 | Val Loss: 0.6531 | Time: 1659.36s
Early stopping...

Epoch 2/3
Train Loss: 0.6223 | Val Loss: 0.6521 | Time: 84.92s
Train Loss: 0.6733 | Val Loss: 0.6460 | Time: 168.88s
Train Loss: 0.6873 | Val Loss: 0.6385 | Time: 253.29s
Train Loss: 0.6902 | Val Loss: 0.6306 | Time: 331.74s
Train Loss: 0.6862 | Val Loss: 0.6246 | Time: 409.16s
Train Loss: 0.6813 | Val Loss: 0.6210 | Time: 494.56s
Train Loss: 0.6821 | Val Loss: 0.6188 | Time: 574.10s
Train Loss: 0.6778 | Val Loss: 0.6179 | Time: 658.34s
Train Loss: 0.6782 | Val Loss: 0.6186 | Time: 742.54s
Train Loss: 0.6747 | Val Loss: 0.6203 | Time: 820.75s
Train Loss: 0.6708 | Val Loss: 0.6253 | Time: 899.29s
Early stopping...

Epoch 3/3
Train Loss: 0.7180 | Val Loss: 0.6288 | Time: 79.08s
Early stopping...

Running experiment with batch_size=32, learning_rate=2e-05, epochs=4

Epoch 1/4
Train Loss: 0.7097 | Val Loss: 0.6943 | Time: 80.08s
Train Loss: 0.6970 | Val Loss: 0.6993 | Time: 159.20s
Train Loss: 0.6915 | Val Loss: 0.6994 | Time: 238.47s
Train Loss: 0.6983 | Val Loss: 0.6986 | Time: 322.86s
Early stopping...

Epoch 2/4
Train Loss: 0.7147 | Val Loss: 0.6935 | Time: 85.17s
Train Loss: 0.7191 | Val Loss: 0.6870 | Time: 172.12s
Train Loss: 0.7141 | Val Loss: 0.6824 | Time: 256.25s
Train Loss: 0.7136 | Val Loss: 0.6790 | Time: 340.43s
Train Loss: 0.7162 | Val Loss: 0.6762 | Time: 418.79s
Train Loss: 0.7110 | Val Loss: 0.6743 | Time: 495.58s
Train Loss: 0.7059 | Val Loss: 0.6734 | Time: 571.99s
Train Loss: 0.7065 | Val Loss: 0.6734 | Time: 656.19s
Train Loss: 0.7021 | Val Loss: 0.6742 | Time: 740.51s
Train Loss: 0.6993 | Val Loss: 0.6753 | Time: 818.79s
Early stopping...

Epoch 3/4
Train Loss: 0.6974 | Val Loss: 0.6753 | Time: 78.79s
Early stopping...

Epoch 4/4
Train Loss: 0.6854 | Val Loss: 0.6769 | Time: 85.14s
Early stopping...

Best Params: batch=32, lr=5e-05, epochs=4

Epoch 1/4
Train Loss: 0.4481 | Val Loss: 0.3890

Epoch 2/4
Train Loss: 0.3844 | Val Loss: 0.3858

Epoch 3/4
Train Loss: 0.4216 | Val Loss: 0.5283

Epoch 4/4
Train Loss: 0.4625 | Val Loss: 0.6001

Final Evaluation
Accuracy: 0.6824 | Precision: 0.6384 | Recall: 0.8417
F1 Score: 0.7261
Confusion Matrix:
[[ 879  801]
 [ 266 1414]]
